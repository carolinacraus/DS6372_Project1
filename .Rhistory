car_df$Style_Sedan <- as.factor(ifelse(car_df$Vehicle.Style == "Sedan",1,0))
car_df$Style_Hatchback <- as.factor(ifelse(car_df$Vehicle.Style == "2dr Hatchback" |
car_df$Vehicle.Style == "4dr Hatchback",1,0))
car_df$Style_Truck <- as.factor(ifelse(car_df$Vehicle.Style == "Crew Cab Pickup"|
car_df$Vehicle.Style == "Extended Cab Pickup"|
car_df$Vehicle.Style == "Regular Cab Pickup", 1, 0))
car_df$Style_Convertible <- as.factor(ifelse(car_df$Vehicle.Style == "Convertible",1,0))
car_df$Style_Wagon <- as.factor(ifelse(car_df$Vehicle.Style == "Wagon",1,0))
car_df <- car_df[,-11]
#car_df <- as.data.frame(car_df)
car_df$Flex_fuel <- as.double(ifelse(car_df$Market.Category == "Flex Fuel,Diesel"|
car_df$Market.Category == "Flex Fuel,Hybrid"|
car_df$Market.Category == "Flex Fuel,Luxury,High-Performance"|
car_df$Market.Category == "Flex Fuel,Performance"|
car_df$Market.Category == "Flex Fuel,Performance,Hybrid"|
car_df$Market.Category == "Flex Fuel"|
car_df$Market.Category == "Flex Fuel,Factory Tuner,Luxury,High-Performance"|
car_df$Market.Category == "Flex Fuel,Luxury"|
car_df$Market.Category == "Flex Fuel,Luxury,Performance"|
car_df$Market.Category == "Flex Fuel,Performance,Hybrid",1,0))
car_df$Crossover <- as.double(ifelse(car_df$Market.Category == "Crossover"|
car_df$Market.Category == "Crossover,Exotic,Luxury,High-Performance"|
car_df$Market.Category == "Crossover,Factory Tuner,Luxury,High-Performance"|
car_df$Market.Category == "Crossover,Flex Fuel,Performance"|
car_df$Market.Category == "Crossover,Hatchback,Factory Tuner,Performance"|
car_df$Market.Category == "Crossover,Hatchback,Performance"|
car_df$Market.Category == "Crossover,Luxury"|
car_df$Market.Category == "Crossover,Diesel"|
car_df$Market.Category == "Crossover,Exotic,Luxury,Performance"|
car_df$Market.Category == "Crossover,Factory Tuner,Luxury,Performance"|
car_df$Market.Category == "Crossover,Flex Fuel"|
car_df$Market.Category == "Crossover,Flex Fuel,Luxury,Performance"|
car_df$Market.Category == "Crossover,Hatchback"|
car_df$Market.Category == "Crossover,Hatchback,Luxury"|
car_df$Market.Category == "Crossover,Hybrid"|
car_df$Market.Category == "Crossover,Luxury,Diesel"|
car_df$Market.Category == "Crossover,Luxury,Hybrid"|
car_df$Market.Category == "Crossover,Luxury,Performance,Hybrid",1,0))
car_df$Diesel <- as.double(ifelse(car_df$Market.Category == "Diesel"|
car_df$Market.Category == "Diesel,Luxury",1,0))
car_df$Exotic <- as.double(ifelse(car_df$Market.Category == "Exotic"|
car_df$Market.Category == "Exotic,Factory Tuner,Luxury,High-Performance"|
car_df$Market.Category == "Exotic,Flex Fuel,Factory Tuner,Luxury,High-Performance"|
car_df$Market.Category == "Exotic,High-Performance"|
car_df$Market.Category == "Exotic,Luxury,High-Performance"|
car_df$Market.Category == "Exotic,Luxury,Performance"|
car_df$Market.Category == "Exotic,Factory Tuner,High-Performance"|
car_df$Market.Category == "Exotic,Factory Tuner,Luxury,Performance"|
car_df$Market.Category == "Exotic,Flex Fuel,Luxury,High-Performance"|
car_df$Market.Category == "Exotic,Luxury"|
car_df$Market.Category == "Exotic,Luxury,High-Performance,Hybrid"|
car_df$Market.Category == "Exotic,Performance",1,0))
car_df$Factory <- as.double(ifelse(car_df$Market.Category == "Factory"|
car_df$Market.Category == "Factory Tuner,High-Performance"|
car_df$Market.Category == "Factory Tuner,Luxury,High-Performance"|
car_df$Market.Category == "Factory Tuner,Performance"|
car_df$Market.Category == "Factory Tuner,Luxury"|
car_df$Market.Category == "Factory Tuner,Luxury,Performance",1,0))
car_df$Hatchback <- as.double(ifelse(car_df$Market.Category == "Hatchback"|
car_df$Market.Category == "Hatchback,Factory Tuner,High-Performance"|
car_df$Market.Category =="Hatchback,Factory Tuner,Performance"|
car_df$Market.Category == "Hatchback,Hybrid"|
car_df$Market.Category == "Hatchback,Luxury,Hybrid"|
car_df$Market.Category == "Hatchback,Performance"|
car_df$Market.Category == "Hatchback,Diesel"|
car_df$Market.Category == "Hatchback,Factory Tuner,Luxury,Performance"|
car_df$Market.Category == "Hatchback,Flex Fuel"|
car_df$Market.Category == "Hatchback,Luxury"|
car_df$Market.Category == "Hatchback,Luxury,Performance",1,0))
car_df$Hybrid <- as.double(ifelse(car_df$Market.Category == "Hybrid",1,0))
car_df$Luxury <- as.double(ifelse(car_df$Market.Category == "Luxury"|
car_df$Market.Category == "Luxury,High-Performance"|
car_df$Market.Category == "Luxury,Hybrid"|
car_df$Market.Category == "Luxury,Performance,Hybrid"|
car_df$Market.Category == "Luxury,High-Performance,Hybrid"|
car_df$Market.Category == "Luxury,Performance",1,0))
car_df$High_Performance <- as.double(ifelse(car_df$Market.Category == "High-Performance",1,0))
car_df$Performance <- as.double(ifelse(car_df$Market.Category == "Performance"|
car_df$Market.Category == "Performance,Hybrid",1,0))
car_df$No_Category <- as.double(ifelse(car_df$Market.Category == "No Category",1,0))
car_df <- car_df[,-9]
car_df$flex_Fuel_intake <- as.double(ifelse(car_df$Engine.Fuel.Type == "flex-fuel (premium unleaded recommended/E85"|
car_df$Engine.Fuel.Type == "flex-fuel (unleaded/natural gas)"|
car_df$Engine.Fuel.Type == "flex-fuel (unleaded/E85)"|
car_df$Engine.Fuel.Type == "flex-fuel (premium unleaded required/E85",1,0))
car_df$diesel_Fuel_intake <- as.double(ifelse(car_df$Engine.Fuel.Type == "diesel",1,0))
car_df$nat_fuel_intake <- as.double(ifelse(car_df$Engine.Fuel.Type == "natrual gas",1,0))
car_df$reg_fuel_intake <- as.double(ifelse(car_df$Engine.Fuel.Type =="regular unleaded",1,0))
car_df$electric_intake <- as.double(ifelse(car_df$Engine.Fuel.Type == "electric",1,0))
car_df$prem_fuel_intake <- as.double(ifelse(car_df$Engine.Fuel.Type == "premium unleaded (required)"|
car_df$Engine.Fuel.Type == "premium unleaded (recommended)",1,0))
car_df <- car_df[,-3]
car_df$German_Build <- as.double(ifelse(car_df$Make == "BMW"|
car_df$Make == "Mercedes-Benz"|
car_df$Make == "Volkswagen"|
car_df$Make == "Audi"|
car_df$Make == "Maybach"|
car_df$Make == "Porsche",1,0))
car_df$french_build <- as.double(ifelse(car_df$Make == "Bugatti",1,0))
car_df$Italy_Build <- as.double(ifelse(car_df$Make == "Alfa Romeo"|
car_df$Make == "Ferrari"|
car_df$Make == "FIAT"|
car_df$Make == "Lamborghini"|
car_df$Make == "Maserati",1,0))
car_df$Japan_build <- as.double(ifelse(car_df$Make == "Acura"|
car_df$Make == "Honda"|
car_df$Make == "Infiniti"|
car_df$Make == "Lexus"|
car_df$Make == "Mazda"|
car_df$Make == "Suzuki"|
car_df$Make == "Subaru"|
car_df$Make == "Nissan"|
car_df$Make == "Scion"|
car_df$Make == "Mitsubishi"|
car_df$Make == "Toyota",1,0))
car_df$finland_build <- as.double(ifelse(car_df$Make == "Saab",1,0))
car_df$Netherlands_build <- as.double(ifelse(car_df$Make == "Spyker",1,0))
car_df$SKorea_build <- as.double(ifelse(car_df$Make == "Genesis"|
car_df$Make == "Hyundai"|
car_df$Make == "Kia",1,0))
car_df$sweden_build <- as.double(ifelse(car_df$Make == "Volvo",1,0))
car_df$UK_build <- as.double(ifelse(car_df$Make == "Aston Martin"|
car_df$Make == "Bentley"|
car_df$Make == "Land Rover"|
car_df$Make == "Lotus"|
car_df$Make == "McLaren"|
car_df$Make == "Rolls-Royce",1,0))
car_df$US_build <- as.double(ifelse(car_df$Make == "Buick"|
car_df$Make == "Cadillac"|
car_df$Make == "Chevrolet"|
car_df$Make == "GMC"|
car_df$Make == "Chrysler"|
car_df$Make == "Dodge"|
car_df$Make == "Ford"|
car_df$Make == "Hummer"|
car_df$Make == "Tesla"|
car_df$Make == "Plymouth"|
car_df$Make == "Pontiac"|
car_df$Make == "Oldsmobile"|
car_df$Make == "Lincoln",1,0))
car_df <- car_df[,-1]
# removing no-numerical categories so that we can viz correlative relationships
car_data_correlations <- car_df[,-c(4,5,7,14:48)]
car_data_correlations<- lapply(car_data_correlations,as.integer)
car_data_correlations<- as.data.frame(car_data_correlations)
# calling cor function to put into var.
corr_data <- cor(car_data_correlations)
# generate the plot
ggcorrplot(corr_data, outline.color = "black", lab = TRUE, title = 'MSRP Correlation Plot')
# car_df which includes feat engineering
set.seed(7)
trainIndex<-createDataPartition(car_df$log_MSRP,p=.8,list=F)  #p: proportion of data in train
training <- car_df[trainIndex,]
validate <- car_df[-trainIndex,]
# backup_df no feat engineering
set.seed(7)
trainIndex_b<-createDataPartition(backup_df$log_MSRP,p=.8,list=F)  #p: proportion of data in train
training_b <- backup_df[trainIndex,]
validate_b <- backup_df[-trainIndex,]
# test/train/validation split for validation sections
set.seed(7)
train_df <- .8
valid_df <- .1
test_df <- .1
sampleSizeTrain <- floor(train_df * nrow(backup_df))
sampleSizeValid <- floor(valid_df * nrow(backup_df))
sampleSizeTest <- floor(test_df * nrow(backup_df))
index_train<- sort(sample(seq_len(nrow(backup_df)), size = sampleSizeTrain))
index_not_train<-setdiff(seq_len(nrow(backup_df)),index_train)
index_valid <- sort(sample(seq_len(nrow(backup_df)),size = sampleSizeValid))
index_test <- sort(sample(seq_len(nrow(backup_df)),size=sampleSizeTest))
car_train <- backup_df[index_train,]
car_valid <- backup_df[index_valid,]
car_test <- backup_df[index_test,]
# removing MSRP
training_slr <- training[,-11]
validate_slr <- validate[,-11]
# linear regression model
car_model_fit <- lm(log_MSRP~Year+log(Engine.HP),training_slr)
# k-fold cross validation (10 fold)
set.seed(7)
train_control<- trainControl(method = "cv", number = 10, repeats = 1)
simple_kfold <- train(log_MSRP~Year+log(Engine.HP),
data=training_slr,
method = "lm", trControl = train_control,
metric = "RMSE")
# view k-fold performance
# print(simple_kfold)
# variance inflation factor
vif(car_model_fit)
# coefficients
summary(car_model_fit)
# confidence intervals for coef.
confint.lm(car_model_fit)
# diagnostics
par(mfrow= c(2,2))
plot(car_model_fit)
# diagnostic check with resid. histogram.
#ols_plot_diagnostics(car_model_fit)
# prediction on validation data
car_model_prediction <- predict(car_model_fit, interval = "predict", newdata = validate_slr)
pred_RMSE <- sqrt(mean((car_model_prediction[,1] - validate_slr$log_MSRP)^2))
# # functions for returning RMSE and ASE
# RMSE_func<- function(error){sqrt(mean(error^2))}
ASE_func <- function(error){mean(error^2)}
#
# RMSE_func(car_model_fit$residuals)
ase <- ASE_func(car_model_fit$residuals)
rsqr <- summary(car_model_fit)$r.squared
adj_rsqr<- summary(car_model_fit)$adj.r.squared
cat("RMSE: ", pred_RMSE, "\nASE: ", ase, "\nR-Squared", rsqr, "\nAdj.R-Squared", adj_rsqr)
hp_style<-backup_df %>% ggplot(aes(log_Engine.HP, log_MSRP, color = Vehicle.Style))+
geom_point(show.legend = FALSE)+
geom_smooth(method = 'lm', show.legend = F) +
ggtitle("Slopes For Vehicle Style Categories")+
xlab('Log Engine Horse Power')+
ylab('Log MSRP')
hp_size<- backup_df %>% ggplot(aes(log_Engine.HP, log_MSRP, color = Vehicle.Size))+
geom_point(show.legend = F)+
geom_smooth(method = 'lm', show.legend = F)+
ggtitle("Slopes For Vehicle Size Categories")+
xlab('Log Engine Horse Power')+
ylab('Log MSRP')
hp_make<- backup_df %>% ggplot(aes(log_Engine.HP, log_MSRP, color = Make))+
geom_point(show.legend = FALSE)+
geom_smooth(method = 'lm', show.legend = F)+
ggtitle("Slopes For Different Vehicle Makes")+
xlab('Log Engine Horse Power')+
ylab('Log MSRP')
hp_cylinder <- backup_df %>% ggplot(aes(log_Engine.HP, log_MSRP, color = Engine.Cylinders))+
geom_point(show.legend = FALSE)+
geom_smooth(method = 'lm', show.legend = F)+
ggtitle("Slopes For Different Engine Cylinders")+
xlab('Log Engine Horse Power')+
ylab('Log MSRP')
gridExtra::grid.arrange(hp_style,
hp_size,
hp_make,
hp_cylinder,
ncol = 2)
aov_1 <- aov(log_MSRP~log_Engine.HP* Vehicle.Size, backup_df)
summary(aov_1) # there is not suff. evidence of a need for interaction
aov_2 <- aov(log_MSRP~log_Engine.HP*Make, backup_df)
summary(aov_2) # there is suff. evidence of a need for an interaction
aov_3 <- aov(log_MSRP~log_Engine.HP*Engine.Cylinders, backup_df)
summary(aov_3)# there is suff. evidence of a need for an interaction
aov_4 <- aov(log_MSRP~log_Engine.HP*Vehicle.Style, backup_df)
summary(aov_4)# there is suff. evidence of a need for an interaction
complex_fit <- lm(log_MSRP~
Year+
log_Engine.HP*Engine.Cylinders+
log(Engine.HP)*Make+
log(Engine.HP)*Vehicle.Style,
training_b) # note not using training
# view coef. etc:
#summary(complex_fit)
# create 2x2 grid for plots
par(mfrow = c(2,2))
# diagnostics check
plot(complex_fit)
#set seed for reprodu. outcome
set.seed(7)
# set crossvalidation parameters (non-repeating)
train_control<- trainControl(method = "cv", number = 10, repeats = 1)
# execute the k-fold cv based on RMSE as key metric
complex_kfold <- train(log_MSRP~ Year+
log_Engine.HP*Engine.Cylinders+
log(Engine.HP)*Make+
log(Engine.HP)*Vehicle.Style,
data=training_b,
method = "lm", trControl = train_control,
metric = "RMSE")
# view results
#print(complex_kfold)
complex_pred <- predict(complex_fit, interval = "predict", newdata = validate_b)
complex_RMSE<- sqrt(mean((complex_pred[,1] - validate_b$log_MSRP)^2))
ASE_func <- function(error){mean(error^2)}
ase <- ASE_func(complex_fit$residuals)
bic <- BIC(complex_fit)
rsqr <- summary(complex_fit)$r.squared
adj_rsqr<- summary(complex_fit)$adj.r.squared
cat("RMSE: ", complex_RMSE, "\nASE: ", ase, "\nR-Squared:", rsqr, "\nAdj.R-Squared:", adj_rsqr, "\nBIC: ",bic)
set.seed(7)
training_glm <- training[,-11]
validate_glm <-validate[,-11]
lambda <- seq(0,.3, by = .01)
fitControl2 <- trainControl(method = "repeatedcv", number = 5, repeats = 1)
glmnet.fit2 <- train(log_MSRP~.,
data = training_glm,
method = "glmnet",
trControl = fitControl2,
tuneGrid = expand.grid(alpha = 1, lambda = lambda))
glmnet.fit2
plot(glmnet.fit2)
#opt.pen2<- glmnet.fit2$finalModel$lambdaOpt
#coef(glmnet.fit2$finalModel,opt.pen2)
set.seed(7)
# remove features not selected by LASSO
glm_df <- training_glm[,!names(training_glm) %in% c("Engine.Cylinders12","Engine.Cylinders16","Style_Sedan",
"nat_fuel_intake","electric_intake","french_build",
"Netherlands_build", "Engine.HP", "Style_Wagon")]
# create glm model
glm_model <- lm(log_MSRP~., glm_df)
# view diagnostics
par(mfrow=c(2,2))
plot(glm_model)
glm_prediction <- predict(glm_model, interval = "predict", newdata = validate_glm)
pred_RMSE <- sqrt(mean((glm_prediction[,1] - validate_glm$log_MSRP)^2))
summary(glm_model)
ASE_func <- function(error){mean(error^2)}
ase <- ASE_func(glm_model$residuals)
bic <- BIC(glm_model)
rsqr <- summary(glm_model)$r.squared
adj_rsqr<- summary(glm_model)$adj.r.squared
cat("RMSE: ", pred_RMSE, "\nASE: ", ase, "\nR-Squared", rsqr, "\nAdj.R-Squared", adj_rsqr, "\nBIC", bic)
np_train <- car_train[,-c(1,3,5:7,9:11,15)]
np_test <- car_test[,-c(1,3,5:7,9:11,15)]
np_valid <- car_valid[,-c(1,3,5:7,9:11,15)]
#set seed for reprodu. outcome
set.seed(7)
# set crossvalidation parameters (non-repeating)
train_control<- trainControl(method = "cv", number = 10, repeats = 1)
# execute the k-fold cv based on RMSE as key metric
knn_cv <- train(log_MSRP~.,
data=np_train,
method = "knn", trControl = train_control,
metric = "RMSE")
knn_cv
# np_train <- training_b[,-c(1,3,5:7,9:11,15)]
# np_test <- validate_b[,-c(1,3,5:7,9:11,15)]
# training data split into input and output
train_x = np_train[,!colnames(np_train)== "log_MSRP"]
train_y = as.numeric(unlist(np_train[,colnames(np_train)=="log_MSRP"]))
# test set split into input and output
test_x = np_test[,!colnames(np_test) == "log_MSRP"]
test_y = as.numeric(unlist(np_test[,colnames(np_test)=="log_MSRP"]))
#knn regression
knn_reg = knnreg(train_x, train_y)
pred_y_knn = predict(knn_reg, test_x)
mse = mean((test_y - pred_y_knn)^2)
mae = MAE(test_y, pred_y_knn)
rmse = RMSE(test_y, pred_y_knn)
cat("MSE: ", mse, "\nMAE: ", mae, "\nRMSE: ", rmse)
set.seed(7)
# training data split into input and output
train_x = np_train[,!colnames(np_train)== "log_MSRP"]
train_y = as.numeric(unlist(np_train[,colnames(np_train)=="log_MSRP"]))
# validation set split into input and output
test_x = np_valid[,!colnames(np_valid) == "log_MSRP"]
test_y = as.numeric(unlist(np_valid[,colnames(np_valid)=="log_MSRP"]))
knn_reg_valid = knnreg(train_x,train_y)
pred_y = predict(knn_reg_valid,test_x)
mse = mean((test_y - pred_y)^2)
mae = MAE(test_y, pred_y)
rmse = RMSE(test_y, pred_y)
cat("MSE: ", mse, "\nMAE: ", mae, "\nRMSE: ", rmse)
np_train<- np_train[,-2]
np_valid <- np_valid[,-2]
par(mfrow= c(2,2))
# tree
tree= rpart::rpart(log_MSRP~.,data = np_train, method = "anova")
rpart::printcp(tree)
rpart::plotcp(tree)
summary(tree)
plot(tree, uniform = TRUE,
main = "classifcation tree for MSRP")
text(tree, use.n = TRUE, all = TRUE, cex=.8)
# tree Cross validation
k <- 10
set.seed(7)
cv_tree <- train(log_MSRP~., data = np_train, method = 'rpart',
trControl = trainControl(method = 'cv', number = k))
print(cv_tree)
# prediction
pred_y = predict(tree, test_x)
plot(pred_y, test_y)
abline(0,1)
#sqrt(mean((pred_y - test_y)^2)) RMSE
#print(data.frame(test_y,pred_y))
# regression analysis
mse = mean((test_y-pred_y)^2)
mae = MAE(test_y,pred_y)
rmse = RMSE(test_y,pred_y)
cat("MSE: ", mse, "\nMAE: ", mae, "\nRMSE: ", rmse)
# viz the pred
x = 1:length(test_y)
plot(x,test_y, col = "red", type = "l", lwd = 2,
main = "Log-MSRP test data prediction")
lines(x, pred_y, col = "blue", lwd = 2)
legend("topright", legend = c("Log-MSRP", "predicted-MSRP"),
fill = c("red", "blue"), col = 2:3, adj = c(0,0.6))
library(rpart.plot)
set.seed(7)
# training data split into input and output
train_x = np_train[,!colnames(np_train)== "log_MSRP"]
train_y = as.numeric(unlist(np_train[,colnames(np_train)=="log_MSRP"]))
# validation set split into input and output
test_x = np_valid[,!colnames(np_valid) == "log_MSRP"]
test_y = as.numeric(unlist(np_valid[,colnames(np_valid)=="log_MSRP"]))
#par(mfrow= c(2,2))
# tree
tree= rpart::rpart(log_MSRP~.,data = np_train, method = "anova")
#rpart::printcp(tree) # errors and CP
#rpart::plotcp(tree) # complexity parameter table
prune_tree <- prune(tree, cp = .01)
# summary (prune_tree)
#summary(tree)
# plot(prune_tree, uniform = T)
# text(prune_tree,uniform=T, all = T, cex = .8)
# plot(tree, uniform = TRUE)
# text(tree, use.n = TRUE, all = TRUE, cex=.8)
rpart.plot(prune_tree) # pruned tree
# prediction
pred_y = predict(tree, test_x)
plot(pred_y, test_y)
abline(0,1)
#sqrt(mean((pred_y - test_y)^2)) #RMSE
#print(data.frame(test_y,pred_y))
# regression analysis
mse = mean((test_y-pred_y)^2)
mae = MAE(test_y,pred_y)
rmse = RMSE(test_y,pred_y)
cat("MSE: ", mse, "\nMAE: ", mae, "\nRMSE: ", rmse)
x = 1:length(test_y)
plot(x,test_y, col = "red", type = "l", lwd = 2,
main = "Log MSRP test data prediction")
lines(x, pred_y, col = "blue", lwd = 2)
legend("topright", legend = c("MSRP", "predicted-MSRP"),
fill = c("red", "blue"), col = 2:3, adj = c(0,0.6))
complex_fit <- lm(log_MSRP~
Year+
log_Engine.HP*Engine.Cylinders+
log(Engine.HP)*Make+
log(Engine.HP)*Vehicle.Style,
training_b) # note not using training
# view coef. etc:
#summary(complex_fit)
# create 2x2 grid for plots
par(mfrow = c(2,2))
# diagnostics check
plot(complex_fit)
#set seed for reprodu. outcome
set.seed(7)
# set crossvalidation parameters (non-repeating)
train_control<- trainControl(method = "cv", number = 10, repeats = 1)
# execute the k-fold cv based on RMSE as key metric
complex_kfold <- train(log_MSRP~ Year+
log_Engine.HP*Engine.Cylinders+
log(Engine.HP)*Make+
log(Engine.HP)*Vehicle.Style,
data=training_b,
method = "lm", trControl = train_control,
metric = "RMSE")
# view results
#print(complex_kfold)
complex_pred <- predict(complex_fit, interval = "predict", newdata = validate_b)
complex_RMSE<- sqrt(mean((complex_pred[,1] - validate_b$log_MSRP)^2))
ASE_func <- function(error){mean(error^2)}
ase <- ASE_func(complex_fit$residuals)
bic <- BIC(complex_fit)
rsqr <- summary(complex_fit)$r.squared
adj_rsqr<- summary(complex_fit)$adj.r.squared
cat("RMSE: ", complex_RMSE, "\nASE: ", ase, "\nR-Squared:", rsqr, "\nAdj.R-Squared:", adj_rsqr, "\nBIC: ",bic)
# removing MSRP
training_slr <- training[,-11]
validate_slr <- validate[,-11]
# linear regression model
car_model_fit <- lm(log_MSRP~Year+log(Engine.HP),training_slr)
# k-fold cross validation (10 fold)
set.seed(7)
train_control<- trainControl(method = "cv", number = c(5,10), repeats = 1)
simple_kfold <- train(log_MSRP~Year+log(Engine.HP),
data=training_slr,
method = "lm", trControl = train_control,
metric = "RMSE")
# removing MSRP
training_slr <- training[,-11]
validate_slr <- validate[,-11]
# linear regression model
car_model_fit <- lm(log_MSRP~Year+log(Engine.HP),training_slr)
# k-fold cross validation (10 fold)
set.seed(7)
train_control<- trainControl(method = "cv", number = 10, repeats = 1)
simple_kfold <- train(log_MSRP~Year+log(Engine.HP),
data=training_slr,
method = "lm", trControl = train_control,
metric = "RMSE")
# view k-fold performance
# print(simple_kfold)
# variance inflation factor
vif(car_model_fit)
# coefficients
summary(car_model_fit)
# confidence intervals for coef.
confint.lm(car_model_fit)
# diagnostics
par(mfrow= c(2,2))
plot(car_model_fit)
# diagnostic check with resid. histogram.
#ols_plot_diagnostics(car_model_fit)
# prediction on validation data
car_model_prediction <- predict(car_model_fit, interval = "predict", newdata = validate_slr)
pred_RMSE <- sqrt(mean((car_model_prediction[,1] - validate_slr$log_MSRP)^2))
# # functions for returning RMSE and ASE
# RMSE_func<- function(error){sqrt(mean(error^2))}
ASE_func <- function(error){mean(error^2)}
#
# RMSE_func(car_model_fit$residuals)
ase <- ASE_func(car_model_fit$residuals)
rsqr <- summary(car_model_fit)$r.squared
adj_rsqr<- summary(car_model_fit)$adj.r.squared
cat("RMSE: ", pred_RMSE, "\nASE: ", ase, "\nR-Squared", rsqr, "\nAdj.R-Squared", adj_rsqr)
